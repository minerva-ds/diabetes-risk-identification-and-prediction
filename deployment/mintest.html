<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test ONNX Model Load</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js"></script>
</head>
<body>
    <script>
        async function runModel() {
            try {
                // Load the ONNX model from the models directory
                const session = await ort.InferenceSession.create('models/catboost_model_no_zipmap.onnx');

                // Prepare input data with 30 features
                const inputData = new Float32Array([
                    0.5, 1.0, 0.3, 0.8, 0.9, 0.2, 0.4, 0.7, 0.1, 0.6,
                    0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.2, 0.1,
                    0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.2, 0.1 // 30 features in total
                ]);
                const inputTensor = new ort.Tensor('float32', inputData, [1, 30]); // Shape [1, 30]

                // Update the feeds object to use the correct input name
                const feeds = { 'input': inputTensor };

                // Run the model
                const results = await session.run(feeds);

                // Log all outputs
                for (const outputName in results) {
                    const outputData = results[outputName].data;
                    console.log(`${outputName}:`, outputData);
                }

                // Access the label directly
                const label = results.label.data[0];
                console.log('Label Result:', label);
            } catch (err) {
                console.error('Error during inference:', err);
            }
        }

        runModel();
    </script>
</body>
</html>
